---
layout:     post
title:      "AVCData数据开发及配置规范"
subtitle:   "如何开发、配置Spark Job任务"
date:       2016-07-05
author:     "xp"
header-img: "img/post-bg-apple-event-2015.jpg"
header-mask: 0.3
catalog:    true
tags:
    - AVCData
    - Hue
    - Oozie
    - Tool
---

> 此处主要说明AVCData数据开发人员在对数据任务进行开发和配置（当前针对[通用数据ETL](http://www.mllearn.com/2016/07/04/how-to-use-spark-hive-executor/)任务）时应当遵循的共同开发规范，若有问题，可与大家协商解决。


## MySQL
**数据库名**、**表名**、**字段名**全部`小写`，不同单词之间用`_`分隔，命名必须***见名知意***或是公司内***通用***的命名习惯及方式。

**数据库名**在进行命名时，需在名称中***指明当前数据库是由哪一个应用所有***，例如，若是`价格监控`应用，则数据库名称字段中应有`price_monitor`关键字。

尽量不要在同一个库、同一个表、甚至同一个字段中出现英文和拼音混用的情况，确定库使用英文或拼音后，后续建表、新建字段都使用同样的英文或拼音表达方式。

库表必须存在**表主键**（联合主键或单独主键），且必须放置在数据库表名的最前面（此为适应通用ETL任务需要）。

**表字段顺序**必须与Spark SQL（或者HiveQL）投影的字段顺序必须一致。

表与表之间的相同表达意思的***字段名称尽量统一***，例如在`web_user`表中的用户ID字段叫`user_id`，那么其他表中，例如`web_group`表中表示用户ID的字段也应该叫做`user_id`，并且相同表达意思的字段在同一个数据库中尽量保持相同的数据类型。

***禁止使用数据库保留字***，避免在应用及其他操作过程中带来不必要的麻烦。

关于***字段内容***，若无特殊要求的情况下，字段串类型的字段设定默认值为`''`，即空串；数据类型的字段设定默认值为`0`，以方便后端服务及前端展现。

***数据库引擎***使用`MyISAM`，数据库及表字符集使用`utf8`。

在合理规划的前提下，尽量用少的存储一个字段的数据。

在考虑数据规模后的前提下，若后续需要对表进行水平分区，考虑当前是否存在合适的字段可以支持日后的分区要求。

后续补充常用字段中文名称及对应英文字段名称的对应关系。


## 项目目录约定
每一个项目对应Git中的一个独立的仓库。

项目根目录中包含如下内容：

- 项目模块名称对应的目录名称，即项目下的`每一个模块对应一个目录`。
- Hue的鉴权信息，以`hue.auth`文件名表示，第一行为登陆用户名，第二行为登陆密码。
- 导出`workflow`的定义以`hue-workflow-documents.json`文件名表式，操作人在每次对workflow定义修改后必须导出最新的定义，覆盖项目根目录下的同名文件并及时`push`至项目仓库中。
- 导出`coordinator`的定义以`hue-coordinator-documents.json`文件名表式，操作人在每次对coordinator定义修改后必须导出最新的定义，覆盖项目根目录下的同名文件并及时`push`至项目仓库中。
- 其他项目通用配置及文件，例如导出数据库连接配置信息。

模块目录中存放HiveQL文件及HiveQL导出数据对应的MySQL建表文件，两种文件名称相同，HiveQL文件使用`.hql`后缀，MySQL建表文件使用`.sql`后缀，即一个HiveQL文件对应一个MySQL数据表文件。


## Oozie配置命名约定
- 不同项目的数据任务配置到对应的Hue项目名称的用户名中。
- 配置`workflow`时，workflow的名称对应需要导出的表的名称，即hql文件的名称，出错后方便后续对问题进行定位。
- workflow的描述信息中尽量包含项目的模块信息，辅助说明此workflow的作用。
- 在编写HiveQL文件时，尽量对文件里的参数支持参数配置化，比如查询日期参数，以此支持历史数据任务的重跑和调度。
- 尽量对每一个调度任务配置通知任务，即任务失败后可以以邮件或短信的方式告知任务负责人进行及时的处理（现阶段提供邮件通知任务，需要自行配置）。


## 其他
后续会根据项目实际情况调整此规范中的相应内容。